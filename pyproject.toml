[project]
name = "ZorkGPT"
version = "0.1.0"
description = "Teaching AI to play the classic text adventure Zork using Large Language Models"
requires-python = ">=3.11"
dependencies = [
    "openai>=1.79.0",
    "pydantic>=2.11.4",
    "requests>=2.31.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
]
s3 = [
    "boto3>=1.34.0",
]

[dependency-groups]
dev = [
    "pytest>=8.3.5",
]

[tool.zorkgpt.llm]
# LLM Configuration
client_base_url = "https://openrouter.ai/api/v1"
agent_model = "deepseek/deepseek-r1-0528-qwen3-8b:free"
info_ext_model = "google/gemma-3-12b-it"
critic_model = "google/gemma-3-12b-it"
analysis_model = "qwen/qwen3-30b-a3b:free"

# client_base_url = "http://192.168.10.109:1234/v1"
# agent_model = "qwen/qwen3-30b-a3b:free"
# info_ext_model = "gemma-3-12b-it-qat"
# critic_model = "gemma-3-12b-it-qat"
# analysis_model = "qwen/qwen3-30b-a3b:free"

[tool.zorkgpt.agent_sampling]
# Agent LLM Sampling Parameters
temperature = 0.5
top_p = 0.95
top_k = 20
min_p = 0.0
# max_tokens = null  # Optional - leave commented to use default

[tool.zorkgpt.critic_sampling]
# Critic LLM Sampling Parameters
temperature = 0.2
max_tokens = 100
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.extractor_sampling]
# Information Extractor LLM Sampling Parameters
temperature = 0.1
max_tokens = 300
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.analysis_sampling]
# Analysis Model LLM Sampling Parameters (for knowledge generation)
temperature = 0.3
top_p = 0.8     # Optional - leave commented for default
top_k = 20     # Optional - leave commented for default
min_p = 0.0     # Optional - leave commented for default
max_tokens = 5000  # Optional - leave commented to use default

[tool.zorkgpt.gameplay]
# Gameplay Configuration
turn_delay_seconds = 30.0
turn_window_size = 100
min_knowledge_quality = 6.0
critic_rejection_threshold = -0.05

[tool.zorkgpt.logging]
# Logging Configuration
enable_prompt_logging = false

[tool.zorkgpt.orchestrator]
# Orchestrator Configuration
max_turns_per_episode = 5000
knowledge_update_interval = 100
map_update_interval = 10
enable_state_export = true
max_context_tokens = 40000
context_overflow_threshold = 0.6

[tool.zorkgpt.files]
# File Configuration
episode_log_file = "zork_episode_log.txt"
json_log_file = "zork_episode_log.jsonl"
state_export_file = "current_state.json"

[tool.zorkgpt.aws]
# AWS Configuration (optional)
s3_key_prefix = "zorkgpt/"
