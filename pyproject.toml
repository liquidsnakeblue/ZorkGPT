[project]
name = "ZorkGPT"
version = "0.1.0"
description = "Teaching AI to play the classic text adventure Zork using Large Language Models"
requires-python = ">=3.11"
dependencies = [
    "openai>=1.79.0",
    "pydantic>=2.11.4",
    "requests>=2.31.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
]
s3 = [
    "boto3>=1.34.0",
]

[dependency-groups]
dev = [
    "pytest>=8.3.5",
]

[tool.zorkgpt.llm]
# LLM Configuration
client_base_url = "https://openrouter.ai/api/v1"
agent_model = "qwen/qwen3-235b-a22b"
info_ext_model = "gemma-3-12b-it-qat"
# info_ext_model = "google/gemma-3-12b-it"
critic_model = "gemma-3-12b-it-qat"
# critic_model = "google/gemma-3-12b-it"
analysis_model = "meta-llama/llama-4-scout"

# Per-model base URLs (optional, for cost optimization)
# If not specified, will fall back to client_base_url
# Examples:
# agent_base_url = "https://api.together.xyz/v1"
info_ext_base_url = "http://oracle.nord:1234/v1"
critic_base_url = "http://oracle.nord:1234/v1"
# analysis_base_url = "https://api.openai.com/v1"

[tool.zorkgpt.retry]
# Retry and Exponential Backoff Configuration
max_retries = 5
initial_delay = 1.0           # Initial retry delay in seconds
max_delay = 60.0              # Maximum retry delay in seconds
exponential_base = 2.0        # Multiplier for exponential backoff
jitter_factor = 0.1           # Random jitter to prevent thundering herd (0.0 to 1.0)
retry_on_timeout = true
retry_on_rate_limit = true
retry_on_server_error = true  # 5xx errors
timeout_seconds = 120.0
# Circuit breaker settings
circuit_breaker_enabled = true
circuit_breaker_failure_threshold = 10    # Number of failures before opening circuit
circuit_breaker_recovery_timeout = 300.0  # Seconds before trying to close circuit
circuit_breaker_success_threshold = 3     # Consecutive successes needed to close circuit

[tool.zorkgpt.agent_sampling]
# Agent LLM Sampling Parameters, taken from Qwen model card
temperature = 0.6
top_p = 0.95
top_k = 20
min_p = 0.0
# max_tokens = null  # Optional - leave commented to use default

[tool.zorkgpt.critic_sampling]
# Critic LLM Sampling Parameters
temperature = 0.2
max_tokens = 100
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.extractor_sampling]
# Information Extractor LLM Sampling Parameters
temperature = 0.1
max_tokens = 400
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.analysis_sampling]
# Analysis Model LLM Sampling Parameters (for knowledge generation)
temperature = 0.3
top_p = 0.8     # Optional - leave commented for default
top_k = 20     # Optional - leave commented for default
min_p = 0.0     # Optional - leave commented for default
max_tokens = 5000  # Optional - leave commented to use default

[tool.zorkgpt.gameplay]
# Gameplay Configuration
turn_delay_seconds = 30.0
turn_window_size = 100
min_knowledge_quality = 6.0
critic_rejection_threshold = -0.2  # More permissive from -0.05 to allow more experimentation
# Exit pruning configuration
enable_exit_pruning = true
exit_failure_threshold = 2  # Reduced from 3 to more quickly abandon failed directions
# Knowledge base condensation configuration  
enable_knowledge_condensation = true
knowledge_condensation_threshold = 15000  # Characters before triggering condensation
# Save/restore configuration
zork_save_filename_template = "zorkgpt_save_{timestamp}.sav"
zork_game_workdir = "game_files"
save_signal_filename = ".SAVE_REQUESTED_BY_SYSTEM"

[tool.zorkgpt.logging]
# Logging Configuration
enable_prompt_logging = false

[tool.zorkgpt.orchestrator]
# Orchestrator Configuration
max_turns_per_episode = 5000
knowledge_update_interval = 100
map_update_interval = 10
objective_update_interval = 25
enable_state_export = true
max_context_tokens = 40000
context_overflow_threshold = 0.6

enable_objective_refinement = true
objective_refinement_interval = 50
max_objectives_before_forced_refinement = 15
refined_objectives_target_count = 8

# Inter-episode synthesis configuration
enable_inter_episode_synthesis = true
persistent_wisdom_file = "persistent_wisdom.md"

[tool.zorkgpt.files]
# File Configuration
episode_log_file = "zork_episode_log.txt"
json_log_file = "zork_episode_log.jsonl"
state_export_file = "current_state.json"

[tool.zorkgpt.aws]
# AWS Configuration (optional)
s3_key_prefix = "zorkgpt/"
